{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42f4647",
   "metadata": {},
   "source": [
    "### Import the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f60205b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cc00d",
   "metadata": {},
   "source": [
    "### # How many samples of each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49fb409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5959ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c495558",
   "metadata": {},
   "source": [
    "### Let's visualize some random training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e39d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I have the biggest crush on you &amp; I dont know if you'll ever know it ??\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@KirCut1 lets get a dope picture together and have the dopest explosion ????\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Suspect in latest theater attack had psychological issues http://t.co/3huhZxliiG\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@DavidCovucci We can't because a sinkhole swallowed every taco place in the neighborhood\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "@Kirafrog @mount_wario Did you get wrecked again?\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d796e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73d049b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db80770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
    "\n",
    "# Before TensorFlow 2.6\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization \n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\"\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vect = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c8fe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vect.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "060ba58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[ 74,   9, 232,   4,  13, 182]], dtype=int64)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city\"\n",
    "text_vect([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbb47b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   7,  46,  22, 884,  10, 148]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
    "text_vect([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33780fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc9ccbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e8b9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41a2987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d95e1d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9, 232,   4,  13, 182,   7,  46,  22, 884,  10, 148,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf45625",
   "metadata": {},
   "source": [
    "## DRAWBACKS of Textvectorization: \n",
    "##           1. creats very huge matrix\n",
    "##           2. results in sparse matrix representation\n",
    "##           3. provides static vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c33b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d63673cb",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b74f604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9ca81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04161851,  0.02555401,  0.03059632, ...,  0.01822953,\n",
       "          0.01464251, -0.04292045],\n",
       "        [ 0.03323453,  0.04985398, -0.00108425, ..., -0.04525739,\n",
       "         -0.04970834, -0.01337311],\n",
       "        [-0.03690611,  0.04052639, -0.03470866, ..., -0.00616246,\n",
       "         -0.03034323,  0.04261291],\n",
       "        ...,\n",
       "        [ 0.00785639,  0.00100154, -0.04740683, ...,  0.037011  ,\n",
       "         -0.0412913 , -0.01938312],\n",
       "        [ 0.00785639,  0.00100154, -0.04740683, ...,  0.037011  ,\n",
       "         -0.0412913 , -0.01938312],\n",
       "        [ 0.00785639,  0.00100154, -0.04740683, ...,  0.037011  ,\n",
       "         -0.0412913 , -0.01938312]]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There is flood in my city\"\n",
    "sample_embed = embedding(text_vectorizer([sample_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c87ab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.04161851,  0.02555401,  0.03059632, -0.01319492,  0.02548862,\n",
       "        0.0184299 ,  0.00765024,  0.01213402, -0.03109097, -0.03191024,\n",
       "        0.0155153 ,  0.03752157, -0.00980986, -0.02124889, -0.01659371,\n",
       "       -0.0180951 ,  0.01655449, -0.02162659, -0.01845462,  0.0122849 ,\n",
       "       -0.03900913, -0.04460765, -0.03791111, -0.0330929 ,  0.02078063,\n",
       "        0.00836837,  0.00143768, -0.03502387, -0.02615548, -0.0005996 ,\n",
       "       -0.03172252,  0.0486537 ,  0.02887782, -0.03824252, -0.0270465 ,\n",
       "       -0.01473473, -0.03352197, -0.04126145, -0.04876558,  0.03251504,\n",
       "        0.0102616 ,  0.03238047, -0.03751427,  0.04423592,  0.0385224 ,\n",
       "        0.03503698, -0.04129225, -0.03040377, -0.01148222,  0.03695824,\n",
       "       -0.00780533, -0.01735145,  0.00818031,  0.0133373 ,  0.04201298,\n",
       "       -0.0063285 , -0.04324958,  0.03536199,  0.04854539,  0.00397132,\n",
       "        0.0234475 ,  0.00103261, -0.00258385, -0.00196835, -0.02755803,\n",
       "        0.0414013 ,  0.04428789,  0.0272562 ,  0.00144947,  0.04730482,\n",
       "       -0.00586121,  0.03336816, -0.02855255, -0.03060292, -0.04434491,\n",
       "       -0.01875269, -0.01084929,  0.04724265,  0.03253651, -0.00820886,\n",
       "       -0.0023527 ,  0.0332731 ,  0.01118107, -0.01196412, -0.00282264,\n",
       "       -0.03638024, -0.04907846,  0.03528274,  0.00616948, -0.03755451,\n",
       "       -0.01420276, -0.02957312, -0.03686812,  0.00021707, -0.04880002,\n",
       "       -0.03744365,  0.04703164,  0.04123857, -0.04995878, -0.00808525,\n",
       "        0.03760416,  0.03468886,  0.03114099,  0.0126505 , -0.00574887,\n",
       "        0.02762285,  0.04155776,  0.02545107, -0.03059933,  0.04998067,\n",
       "       -0.02989804,  0.03961108,  0.01743433,  0.04535763, -0.01298117,\n",
       "       -0.03640232, -0.03909817, -0.01559012,  0.04969052,  0.04105307,\n",
       "       -0.0184078 , -0.03048037,  0.01752027,  0.02757362,  0.03836239,\n",
       "        0.01822953,  0.01464251, -0.04292045], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "005489f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f856ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fba0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 29ms/step - loss: 0.5200 - accuracy: 0.7355 - val_loss: 0.4586 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.3214 - accuracy: 0.8686 - val_loss: 0.4956 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.2224 - accuracy: 0.9134 - val_loss: 0.5762 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.1536 - accuracy: 0.9458 - val_loss: 0.6730 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.1084 - accuracy: 0.9596 - val_loss: 0.8165 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_history = model.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1509290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[1.5833689e-02],\n",
       "        [7.2575074e-01],\n",
       "        [9.9856305e-01],\n",
       "        [4.7345631e-02],\n",
       "        [4.5973939e-04],\n",
       "        [9.9703228e-01],\n",
       "        [9.2987216e-01],\n",
       "        [9.9937958e-01],\n",
       "        [9.9713320e-01],\n",
       "        [2.9848439e-01]], dtype=float32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_pred_probs = model.predict(val_sentences)\n",
    "model_pred_probs.shape, model_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "266df5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### We can turn these prediction probabilities into prediction classes by rounding to the nearest integer \n",
    "### (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1).\n",
    "\n",
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_preds = tf.squeeze(tf.round(model_pred_probs))\n",
    "model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94879ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.11548556430446"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "model_acc = accuracy_score(val_labels, model_preds) * 100\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7fa637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ec68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5d6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f28b56c1",
   "metadata": {},
   "source": [
    "### Model 2: GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101706c",
   "metadata": {},
   "source": [
    "* Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
    "\n",
    "* The GRU cell has similar features to an LSTM cell but has less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f1b8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GRU(64)(x) # return vector for whole sequence\n",
    "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40abcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b93f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 26ms/step - loss: 0.2071 - accuracy: 0.9129 - val_loss: 0.6366 - val_accuracy: 0.7651\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.1016 - accuracy: 0.9628 - val_loss: 0.8728 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0719 - accuracy: 0.9708 - val_loss: 1.1175 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.0623 - accuracy: 0.9745 - val_loss: 1.1688 - val_accuracy: 0.7651\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0618 - accuracy: 0.9730 - val_loss: 1.2828 - val_accuracy: 0.7612\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "300c77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[1.9721978e-03],\n",
       "        [7.3158938e-01],\n",
       "        [9.9994552e-01],\n",
       "        [1.6574892e-01],\n",
       "        [2.8520526e-05],\n",
       "        [9.9995482e-01],\n",
       "        [9.9671900e-01],\n",
       "        [9.9997663e-01],\n",
       "        [9.9996781e-01],\n",
       "        [8.6742634e-01]], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_pred_probs = model.predict(val_sentences)\n",
    "model_pred_probs.shape, model_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c250c6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = tf.squeeze(tf.round(model_pred_probs))\n",
    "model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "838f1cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.11548556430446"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "model_acc = accuracy_score(val_labels, model_preds) * 100\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2e877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4dec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07172c1",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectonal RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3e6c8",
   "metadata": {},
   "source": [
    "* A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
    " * In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
    "\n",
    "* However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8794e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "936ed448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5fa15a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 13s 34ms/step - loss: 0.5123 - accuracy: 0.7419 - val_loss: 0.4605 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.3140 - accuracy: 0.8704 - val_loss: 0.5248 - val_accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.2116 - accuracy: 0.9200 - val_loss: 0.5771 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.1409 - accuracy: 0.9539 - val_loss: 0.6636 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 29ms/step - loss: 0.1006 - accuracy: 0.9651 - val_loss: 0.7080 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "680c5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0978686 ],\n",
       "       [0.90104336],\n",
       "       [0.99965   ],\n",
       "       [0.30254355],\n",
       "       [0.0058037 ],\n",
       "       [0.9983175 ],\n",
       "       [0.96804327],\n",
       "       [0.99970883],\n",
       "       [0.99980676],\n",
       "       [0.20917854]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f290b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f62fe6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.37795275590551"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "model_acc = accuracy_score(val_labels, model_4_preds) * 100\n",
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7a94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b0f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07b00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c58b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
