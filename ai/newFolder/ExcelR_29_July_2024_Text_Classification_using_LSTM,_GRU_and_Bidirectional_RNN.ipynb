{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e42f4647",
      "metadata": {
        "id": "e42f4647"
      },
      "source": [
        "### Import the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z0dbf_Y-voCa",
      "metadata": {
        "id": "z0dbf_Y-voCa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60205b4",
      "metadata": {
        "id": "f60205b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/9. Artificial Intelligence/3. Presentations/AI PPT Materials Day 1-30/Day 20/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/9. Artificial Intelligence/3. Presentations/AI PPT Materials Day 1-30/Day 20/test.csv\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b0cc00d",
      "metadata": {
        "id": "8b0cc00d"
      },
      "source": [
        "### # How many samples of each class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fb409d",
      "metadata": {
        "id": "49fb409d"
      },
      "outputs": [],
      "source": [
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5959ba4",
      "metadata": {
        "id": "c5959ba4"
      },
      "outputs": [],
      "source": [
        "train_df_shuffled = train_df.sample(frac=1,\n",
        "                                    random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c495558",
      "metadata": {
        "id": "9c495558"
      },
      "source": [
        "### Let's visualize some random training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e39d426",
      "metadata": {
        "id": "5e39d426"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random_index = random.randint(0,\n",
        "                              len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\",\n",
        "        \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d796e083",
      "metadata": {
        "id": "d796e083"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d049b4",
      "metadata": {
        "id": "73d049b4"
      },
      "outputs": [],
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db80770",
      "metadata": {
        "id": "0db80770"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
        "\n",
        "# Before TensorFlow 2.6\n",
        "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
        "# you can use: \"tf.keras.layers.TextVectorization\"\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vect = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c8fe905",
      "metadata": {
        "id": "8c8fe905"
      },
      "outputs": [],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vect.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060ba58a",
      "metadata": {
        "id": "060ba58a"
      },
      "outputs": [],
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There is flood in my city\"\n",
        "text_vect([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb47b20",
      "metadata": {
        "id": "fbb47b20"
      },
      "outputs": [],
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
        "text_vect([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4d6c01",
      "metadata": {
        "id": "3c4d6c01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33780fb0",
      "metadata": {
        "id": "33780fb0"
      },
      "outputs": [],
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc9ccbcc",
      "metadata": {
        "id": "dc9ccbcc"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e8b9cf5",
      "metadata": {
        "id": "3e8b9cf5"
      },
      "outputs": [],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a2987e",
      "metadata": {
        "id": "41a2987e"
      },
      "outputs": [],
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There is flood in my city\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95e1d70",
      "metadata": {
        "id": "d95e1d70"
      },
      "outputs": [],
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There is flood in my city and we are looking for help\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf45625",
      "metadata": {
        "id": "bcf45625"
      },
      "source": [
        "## DRAWBACKS of Textvectorization:\n",
        "##           1. creats very huge matrix\n",
        "##           2. results in sparse matrix representation\n",
        "##           3. provides static vector representation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63673cb",
      "metadata": {
        "id": "d63673cb"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b74f604",
      "metadata": {
        "id": "7b74f604"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ca81fa",
      "metadata": {
        "id": "c9ca81fa"
      },
      "outputs": [],
      "source": [
        "sample_sentence = \"There is flood in my city\"\n",
        "sample_embed = embedding(text_vectorizer([sample_sentence]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c87ab33",
      "metadata": {
        "id": "9c87ab33"
      },
      "outputs": [],
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "005489f2",
      "metadata": {
        "id": "005489f2"
      },
      "outputs": [],
      "source": [
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,),\n",
        "                      dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "x = layers.Dense(64,\n",
        "                 activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1,\n",
        "                       activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs,\n",
        "                       outputs,\n",
        "                       name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f856ac7",
      "metadata": {
        "id": "0f856ac7"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fba0446",
      "metadata": {
        "id": "0fba0446"
      },
      "outputs": [],
      "source": [
        "# Fit model\n",
        "model_history = model.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1509290",
      "metadata": {
        "id": "c1509290"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_pred_probs = model.predict(val_sentences)\n",
        "model_pred_probs.shape, model_pred_probs[:10] # view the first 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266df5c7",
      "metadata": {
        "id": "266df5c7"
      },
      "outputs": [],
      "source": [
        "### We can turn these prediction probabilities into prediction classes by rounding to the nearest integer\n",
        "### (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1).\n",
        "\n",
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_preds = tf.squeeze(tf.round(model_pred_probs))\n",
        "model_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94879ee0",
      "metadata": {
        "id": "94879ee0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model_acc = accuracy_score(val_labels, model_preds) * 100\n",
        "model_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f28b56c1",
      "metadata": {
        "id": "f28b56c1"
      },
      "source": [
        "### Model 2: GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3101706c",
      "metadata": {
        "id": "3101706c"
      },
      "source": [
        "* Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "* The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f1b8152",
      "metadata": {
        "id": "0f1b8152"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(1,),\n",
        "                      dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x) # return vector for whole sequence\n",
        "x = layers.Dense(64,\n",
        "                 activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1,\n",
        "                       activation=\"sigmoid\")(x)\n",
        "model = tf.keras.Model(inputs,\n",
        "                       outputs,\n",
        "                       name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40abcaba",
      "metadata": {
        "id": "40abcaba"
      },
      "outputs": [],
      "source": [
        "# Compile GRU model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b93f332",
      "metadata": {
        "id": "1b93f332"
      },
      "outputs": [],
      "source": [
        "model_history = model.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300c77d6",
      "metadata": {
        "id": "300c77d6"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_pred_probs = model.predict(val_sentences)\n",
        "model_pred_probs.shape, model_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c250c6ee",
      "metadata": {
        "id": "c250c6ee"
      },
      "outputs": [],
      "source": [
        "model_preds = tf.squeeze(tf.round(model_pred_probs))\n",
        "model_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838f1cc2",
      "metadata": {
        "id": "838f1cc2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model_acc = accuracy_score(val_labels, model_preds) * 100\n",
        "model_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b07172c1",
      "metadata": {
        "id": "b07172c1"
      },
      "source": [
        "### Model 3: Bidirectonal RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace3e6c8",
      "metadata": {
        "id": "ace3e6c8"
      },
      "source": [
        "* A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        " * In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "* However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8794e1e",
      "metadata": {
        "id": "e8794e1e"
      },
      "outputs": [],
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,),\n",
        "                      dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1,\n",
        "                       activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs,\n",
        "                         outputs,\n",
        "                         name=\"model_4_Bidirectional\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936ed448",
      "metadata": {
        "id": "936ed448"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa15a17",
      "metadata": {
        "id": "5fa15a17"
      },
      "outputs": [],
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680c5ef8",
      "metadata": {
        "id": "680c5ef8"
      },
      "outputs": [],
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f290b8c1",
      "metadata": {
        "id": "f290b8c1"
      },
      "outputs": [],
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62fe6d6",
      "metadata": {
        "id": "f62fe6d6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model_acc = accuracy_score(val_labels, model_4_preds) * 100\n",
        "model_acc"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
